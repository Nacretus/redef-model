# -*- coding: utf-8 -*-
"""TOXIC_cnn_bilstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ekgNReC5DuDYVzpF0eGvxfkTErRfvR5w
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

import pandas as pd
import tensorflow as tf
import numpy as np
from numpy import asarray, zeros
from sklearn.model_selection import train_test_split
import re
import string

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, Conv1D, GlobalAveragePooling1D, Bidirectional, LSTM, Dense, Dropout, Concatenate, Dot, Activation
from tensorflow.keras.models import Model
import tensorflow.keras.backend as K
from tensorflow.keras.optimizers import RMSprop, Adam, AdamW, Nadam
from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc, accuracy_score, precision_score, recall_score

# Check if GPU is available
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        # Optional: set memory growth so it doesn't allocate all memory at once
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("✅ GPU is set for training!")
    except RuntimeError as e:
        print(e)

# Set seeds for reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

# 1. Data Loading with Language Column
encodings = ['utf-8', 'utf-8-sig', 'latin1', 'ISO-8859-1']
df = None
for encoding in encodings:
    try:
        df = pd.read_csv('/content/drive/MyDrive/things/FF.csv', encoding=encoding)
        break
    except UnicodeDecodeError:
        continue

if df is None:
    raise ValueError("Failed to load CSV file with all attempted encodings")

df.head()

print(f'total number of datas: {len(df)}')

x = df.iloc[:, 1:].sum()
print(f'number comment per label taking to account the co-occurences:\n{x}')

rowsum = df.iloc[:, 1:].sum(axis=1)
print(rowsum)

no_label_count = 0
for i, count in rowsum.items():
    if count == 0:
        no_label_count += 1

print(f'total number of comments: {len(df)}')
print(f'total number of comments without label: {no_label_count}')
print(f'total number of labels: {x.sum()}')

import seaborn as sns
import matplotlib.pyplot as plt

# sns.set(color_codes=True)
comment_len = df.comment.str.len()
sns.histplot(comment_len,kde=False, color="blue")
plt.xlim(0, 2500)

plt.xlabel('Comment Length')

# Display the plot
plt.show()

rowsums = df.iloc[:, 1:].sum(axis=1)
temp = df.iloc[:, 1:]
train_corr = temp[rowsums > 0]
corr = df.iloc[:, 1:].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr,
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values, annot=True, cmap="Blues")

# Modify the normalize_text function
def normalize_text(text):
    text = text.lower()
    text = re.sub(r'(.)\1{2,}', r'\1', text)
    text = str(text).replace("\n", " ")
    text = re.sub(r'[^\w\s]',' ',text)
    text = re.sub('https?://\S+|www\.\S+', ' ', text)
    text = re.sub('[0-9]',"",text)
    text = re.sub(" +", " ", text)
    text = re.sub("([^\x00-\x7F])+"," ",text)
    return text

# Split data into train, validation, and test sets (70-15-15)
X = df['comment']
y = df[df.columns[1:]].values

# Stratified split to maintain label distribution
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=SEED)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)

X_train = X_train.apply(normalize_text)
X_val = X_val.apply(normalize_text)
X_test = X_test.apply(normalize_text)

# prompt: save in a csv file the (X_train, y_train), (X_val, y_val), (X_test, y_test)

import pandas as pd
import numpy as np

# Assuming X_train, y_train, X_val, y_val, X_test, and y_test are already defined

# Convert NumPy arrays to lists if they are not already lists
if isinstance(X_train, np.ndarray):
  X_train = X_train.tolist()
if isinstance(y_train, np.ndarray):
  y_train = y_train.tolist()
if isinstance(X_val, np.ndarray):
  X_val = X_val.tolist()
if isinstance(y_val, np.ndarray):
  y_val = y_val.tolist()
if isinstance(X_test, np.ndarray):
  X_test = X_test.tolist()
if isinstance(y_test, np.ndarray):
  y_test = y_test.tolist()

# Create dataframes
train_df = pd.DataFrame({'X_train': X_train, 'y_train': y_train})
val_df = pd.DataFrame({'X_val': X_val, 'y_val': y_val})
test_df = pd.DataFrame({'X_test': X_test, 'y_test': y_test})


# Save to CSV files
train_df.to_csv('train_data.csv', index=False)
val_df.to_csv('val_data.csv', index=False)
test_df.to_csv('test_data.csv', index=False)

print(f'X_train shape: {X_train.shape}')
print(f'X_val shape: {X_val.shape}')
print(f'X_test shape: {X_test.shape}')

# print 10 comments from each labels on the X_test, y_test

def print_comments_by_label(X_test, y_test):
    """Prints 10 comments from each label in the test set."""

    labels = df.columns[1:]  # Assuming labels are in columns after 'comment'

    for i, label in enumerate(labels):
        print(f"\nComments for label: {label}")
        # Convert y_test to a NumPy array for proper slicing
        y_test_array = np.array(y_test)
        label_indices = np.where(y_test_array[:, i] == 1)[0]  # Indices where label is present

        # Ensure we print only up to 10 comments
        for j in range(min(10, len(label_indices))):
          index = label_indices[j]
          print(f"  Comment {j+1}: {X_test.iloc[index]}")

print_comments_by_label(X_test, y_test)

# make a list that will show the words for each labels use word cloud

import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt

def generate_wordclouds(X_test, y_test):
    """Generates word clouds for each label."""
    labels = df.columns[1:]

    for i, label in enumerate(labels):
        print(f"\nWord cloud for label: {label}")

        # Convert y_test to a NumPy array for proper slicing
        y_test_array = np.array(y_test)
        label_indices = np.where(y_test_array[:, i] == 1)[0]  # Indices where label is present
        label_comments = X_test.iloc[label_indices].tolist()

        # Combine comments for the current label into a single string
        text = " ".join(label_comments)

        wordcloud = WordCloud(width=800, height=400, background_color='black').generate(text)

        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title(f'Word Cloud for Label: {label}')
        plt.show()

generate_wordclouds(X_test, y_test)

# Tokenization and Padding
max_features = 20000
max_len = 500

tokenizer = Tokenizer(num_words=max_features, oov_token='<UNK>')
tokenizer.fit_on_texts(X_train)

# Convert texts to sequences and pad
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_val_seq = tokenizer.texts_to_sequences(X_val)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')

# save the tokenizer to a json file

import json

# Assuming 'tokenizer' is already defined from the previous code
tokenizer_json = tokenizer.to_json()
with open('tokenizer.json', 'w', encoding='utf-8') as f:
    f.write(json.dumps(tokenizer_json, ensure_ascii=False))

# Load GloVe embeddings
embed_size = 300
embeddings_dictionary = dict()
glove_file = open('/content/drive/MyDrive/things/glove.6B.300d.txt', 'r', encoding='utf-8')  # Update path

for line in glove_file:
    records = line.split()
    word = records[0]
    vector = asarray(records[1:], dtype='float32')
    embeddings_dictionary[word] = vector
glove_file.close()

# Create embedding matrix
vocab_size = len(tokenizer.word_index) + 1
num_words = min(max_features, vocab_size)
embedding_matrix = zeros((num_words, embed_size))

for word, i in tokenizer.word_index.items():
    if i >= max_features:
        continue
    embedding_vector = embeddings_dictionary.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector

covered = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))
print(f'Coverage in embedding matrix: {covered}/{embedding_matrix.shape[0]}')

# Create TensorFlow Datasets
batch_size = 128
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_pad, y_train))
val_dataset = tf.data.Dataset.from_tensor_slices((X_val_pad, y_val))
test_dataset = tf.data.Dataset.from_tensor_slices((X_test_pad, y_test))

labels = ['toxic',	'insult',	'profanity',	'threat',	'identity hate',	'very_toxic']
y_train_df = pd.DataFrame(y_train, columns=labels)

for col in labels:
  print(y_train_df[col].value_counts())
  print('\n')

labels = ['toxic',	'insult',	'profanity',	'threat',	'identity hate',	'very_toxic']
y_val_df = pd.DataFrame(y_val, columns=labels)

for col in labels:
  print(y_val_df[col].value_counts())
  print('\n')

labels = ['toxic',	'insult',	'profanity',	'threat',	'identity hate',	'very_toxic']
y_test_df = pd.DataFrame(y_test, columns=labels)

for col in labels:
  print(y_test_df[col].value_counts())
  print('\n')

# Shuffle and batch
train_dataset = train_dataset.cache().shuffle(16000).batch(batch_size).prefetch(8)
val_dataset = val_dataset.cache().batch(batch_size).prefetch(8)
test_dataset = test_dataset.cache().batch(batch_size).prefetch(8)

sequence_input = Input(shape=(max_len,))

x = Embedding(input_dim=num_words,output_dim=embed_size,weights=[embedding_matrix],trainable=False)(sequence_input)
x = SpatialDropout1D(0.2)(x)

x = Conv1D(64, kernel_size=3, padding="valid", kernel_initializer="glorot_uniform")(x)

x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)

avg_pool = GlobalAveragePooling1D()(x)

x = Dense(128, activation='relu', kernel_initializer='he_uniform')(avg_pool)
x = Dropout(0.1)(x)

preds = Dense(6, activation="sigmoid", kernel_initializer="glorot_uniform")(x)

model = Model(sequence_input, preds)

#model.layers[1].trainable = False

model.compile(loss='binary_crossentropy',optimizer=Nadam(learning_rate=1e-3),metrics=[
            tf.keras.metrics.Precision(name='prec'),
             tf.keras.metrics.Recall(name='rec'),
             tf.keras.metrics.AUC(name='auc')])
model.summary()

checkpoint_path = "best_model_Nadam.keras"

cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path,
    save_weights_only=False,   # save full model
    monitor='val_loss',        # metric to track
    save_best_only=True,       # only save when it improves
    mode='min'                 # val_loss: lower is better
)

# Train with embedding frozen
history_frozen = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=5,      # just a few epochs
    callbacks=[cp_callback],
    verbose=1
)

# prompt: plot the precision, recall, loss, auc for the train and val

# Plot training history
plt.figure(figsize=(12, 8))

# Plot loss
plt.subplot(2, 2, 1)
plt.plot(history_frozen.history['loss'], label='Train Loss')
plt.plot(history_frozen.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss')

# Plot precision
plt.subplot(2, 2, 2)
plt.plot(history_frozen.history['prec'], label='Train Precision')
plt.plot(history_frozen.history['val_prec'], label='Validation Precision')
plt.legend()
plt.title('Precision')

# Plot recall
plt.subplot(2, 2, 3)
plt.plot(history_frozen.history['rec'], label='Train Recall')
plt.plot(history_frozen.history['val_rec'], label='Validation Recall')
plt.legend()
plt.title('Recall')

# Plot AUC
plt.subplot(2, 2, 4)
plt.plot(history_frozen.history['auc'], label='Train AUC')
plt.plot(history_frozen.history['val_auc'], label='Validation AUC')
plt.legend()
plt.title('AUC')

plt.tight_layout()
plt.show()

import numpy as np
from sklearn.metrics import f1_score

# Get predictions and true labels
y_probs = model.predict(test_dataset)
y_true = np.concatenate([y for x, y in test_dataset], axis=0)

# Find optimal threshold for each label
best_thresholds = []
for i in range(y_true.shape[1]):
    f1s = []
    thresholds = np.linspace(0.0, 1.0, 101)  # Covers 0.00 to 1.00 in 0.01 steps
    for t in thresholds:
        y_pred_label = (y_probs[:, i] > t).astype(int)
        f1 = f1_score(y_true[:, i], y_pred_label, zero_division=0)  # Handle division warnings
        f1s.append(f1)

    best_idx = np.argmax(f1s)
    best_t = thresholds[best_idx]
    best_f1 = f1s[best_idx]

    best_thresholds.append(best_t)
    print(f"Label {i}: Best Threshold = {best_t:.4f}, F1-Score = {best_f1:.4f}")

best_thresholds = np.array(best_thresholds)

y_pred = (y_probs > best_thresholds).astype(int)

print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=df.columns[1:]))

print("ROC AUC Score:", roc_auc_score(y_test, y_pred))

# prompt: i want to print the confusion matrix of each labels

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate and plot confusion matrices for each label
for i, label in enumerate(df.columns[1:]):
    cm = confusion_matrix(y_true[:, i], y_pred[:, i])
    plt.figure(figsize=(6, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=['Predicted Negative', 'Predicted Positive'],
                yticklabels=['Actual Negative', 'Actual Positive'])
    plt.title(f'Confusion Matrix for {label}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

#model.save('ten_epoch_Nadam.keras')

"""continue training"""

# Re‑load the best model from the checkpoint
best_model = tf.keras.models.load_model("best_model_Nadam.keras")

# Continue training for epochs 5→10
history2 = best_model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=10,               # final epoch number
    initial_epoch=5,         # start from where you left off
    callbacks=[cp_callback], # keep saving further improvements
    verbose=1
)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate and plot confusion matrices for each label
for i, label in enumerate(df.columns[1:]):
    cm = confusion_matrix(y_true[:, i], y_pred[:, i])
    plt.figure(figsize=(6, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=['Predicted Negative', 'Predicted Positive'],
                yticklabels=['Actual Negative', 'Actual Positive'])
    plt.title(f'Confusion Matrix for {label}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

from sklearn.metrics import precision_recall_curve

for i in range(y_true.shape[1]):
    precision, recall, thresholds = precision_recall_curve(y_true[:, i], y_probs[:, i])
    f1s = 2 * (precision * recall) / (precision + recall + 1e-8)  # Avoid division by 0
    best_idx = np.argmax(f1s)
    best_t = thresholds[best_idx]
    print(f"Label {i}: Best Threshold = {best_t:.4f}")

y_pred = (y_probs > best_thresholds).astype(int)

print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=df.columns[1:]))

print("ROC AUC Score:", roc_auc_score(y_test, y_pred))

"""getting the threshold on balance precision and recall"""

from sklearn.metrics import precision_recall_curve
import numpy as np

# Get predictions and true labels
y_probs = model.predict(test_dataset)
y_true = np.concatenate([y for x, y in test_dataset], axis=0)

# Find the threshold where precision and recall are balanced
best_thresholds = []
for i in range(y_true.shape[1]):
    precision, recall, thresholds = precision_recall_curve(y_true[:, i], y_probs[:, i])

    # Find the threshold where precision and recall are closest
    diff = np.abs(precision - recall)  # Compute the absolute difference
    best_idx = np.argmin(diff)  # Find index where difference is minimal
    best_t = thresholds[best_idx]

    print(f"Label {i}: Best Threshold (Precision = Recall) = {best_t:.4f}, Precision = {precision[best_idx]:.4f}, Recall = {recall[best_idx]:.4f}")

    best_thresholds.append(best_t)

best_thresholds = np.array(best_thresholds)

"""continue training from 10 ->15"""

#best_model.save('final_model_15_epoch.keras')

"""INFERENCING"""

def preprocess_texts(texts, tokenizer, max_len):
    sequences = tokenizer.texts_to_sequences(texts)
    padded = pad_sequences(sequences, maxlen=max_len, padding='post')
    return padded

# Example label names
label_names = ['toxic',	'insult',	'profanity',	'threat',	'identity hate',	'very_toxic']

# Example: you should replace this with the actual thresholds you computed
best_thresholds = np.array([0.4655, 0.4460, 0.5099, 0.4550, 0.2839, 0.5513])
#0.34, 0.33, 0.36, 0.65, 0.39, 0.40
def predict_texts(texts, model, tokenizer, max_len, thresholds, labels):
    X_input = preprocess_texts(texts, tokenizer, max_len)
    probs = model.predict(X_input)
    preds = (probs > thresholds).astype(int)

    for i, text in enumerate(texts):
        print(f"\n📝 Text: {text}")
        pred_labels = [labels[j] for j in range(len(labels)) if preds[i][j] == 1]
        print(f"🚩 Predicted Labels: {pred_labels if pred_labels else ['Not Toxic']}")

predict_texts(
    ["You are the worst!", "Srsly Slayed anime. Ang petmalu! #PinoyPride","why do i care?", "bakla kang tangina ka",
     "ewan ko sayo mukha kang nigga","goodmorning everyone!!","I think viral challenges is so fresh! Slay naman ang barkada.",
     "sana mamatay ka na bitch!!", "fuck this shit im done","papatyin kita!","i will kill you",
     "Ganyan talaga kayo mga lumad. walang pinag-aralan."],
    model,
    tokenizer,
    max_len,
    best_thresholds,
    label_names
)

#no_5 = load_model('best_model.keras')

"""new_tresh = np.array([0.39, 0.25, 0.21, 0.53, 0.46, 0.49])
predict_texts(
    ["You are the worst!", "nakita mo yung assignement kanina?","why do i care bakla kang tangina ka",
     "ewan ko sayo mukha kang nigga","goodmorning everyone!!","eto ay isang sample comment",
     "sana mamatay ka na bitch!!", "fuck this shit im done","papatyin kita!"],
    no_5,
    tokenizer,
    max_len,
    best_thresholds,
    label_names
)"""